{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 7: Data Description & Preprocessing with Input Data Visualization\n",
    "### OCEN 460\n",
    "### Team: _/Sample_Text/\n",
    "### Members: Nate Baker and James Frizzel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\jafri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.1-cp39-cp39-win_amd64.whl (10.5 MB)\n",
      "     --------------------------------------- 10.5/10.5 MB 46.7 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.18.5\n",
      "  Downloading numpy-1.22.3-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "     --------------------------------------- 14.7/14.7 MB 36.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jafri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "     ------------------------------------- 503.5/503.5 KB 32.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jafri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.22.3 pandas-1.4.1 pytz-2022.1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install pandas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "#Github: https://github.com/jafrizzell/coral-prediction.git\n",
    "#Describe Datasets and project idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The World Ocean Atlas (WOA) data cannot be shown in it's raw for here because it is too large to be shared in teh github repository where the data is stored. The metadata for it looks as follows. Replace temperature with \"salinity\" or \"dissolved oxygen\" for the other two datasets collected from WAO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude | Longitude | Temperature@0m depth (Celsius) | Temp@5m | Temp@10m | Temp@15m |...| Temp@5500m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Deep Sea Coral Data (DSC) has the following metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude | Longitude | Depth (m) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The deep sea coral dataset reports latitude and longitude of known coral growth locations with the depth at which the coral is growing. The World Ocean Atlas reports depth measurements in increments of 5 meters for depths of 0 to 100 meters, 10 meters for 100 to 500 meters, 50 meters for 500 to 2000 meters, and in 100 meters for greater than 2000 meters. The following code was used and adjusted to round the Deep Sea Coral dataset to match this convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = 'C:/Users/jafri/Documents/GitHub/coral-prediction/processed_data/deep_sea_corals_rounded.csv'\n",
    "\n",
    "raw = pd.read_csv(path)\n",
    "\n",
    "def round_depth(x, base):\n",
    "    return int(base * round(float(x)/base))\n",
    "\n",
    "\n",
    "raw['depth'] = raw['depth'].apply(lambda x: round_depth(x, base=5))\n",
    "\n",
    "raw = raw[raw.depth >= 0]\n",
    "print(len(raw))\n",
    "raw.to_csv('C:/Users/jafri/Documents/GitHub/coral-prediction/processed_data/deep_sea_corals_rounded_depthcorr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The following code aligns latitude and longitude values from the Deep Sea Coral dataset with the lat/long values from the WOA dataset with a tolerance of 0.5 degrees. Second_param file can be changed to indicate the oceanographic variable of interest. WOA data is right-joined to DSC data for further preprocessing. \n",
    "### The code yields a .csv file that contains the DSC data and the WOA data. The WOA data is depth-stratified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import geopandas\n",
    "\n",
    "coral = 'D:/TAMU Work/TAMU 2022 SPRING/OCEN 460/depthtempsal_short2.csv'\n",
    "second_param = 'D:/TAMU Work/TAMU 2022 SPRING/OCEN 460/woa18_all_O00mn01.csv'  # \"O00mn01\" indicates O2 data\n",
    "\n",
    "raw_coral = pd.read_csv(coral)\n",
    "raw_coral = geopandas.GeoDataFrame(raw_coral, geometry=geopandas.points_from_xy(raw_coral.longitude, raw_coral.latitude))\n",
    "raw_coral.depth = raw_coral.depth.astype(float)\n",
    "raw_coral.latitude = raw_coral.latitude.astype(float)\n",
    "raw_coral.longitude = raw_coral.longitude.astype(float)\n",
    "\n",
    "raw_param = pd.read_csv(second_param)\n",
    "raw_param = raw_param.astype(float)\n",
    "raw_param = geopandas.GeoDataFrame(raw_param, geometry=geopandas.points_from_xy(raw_param.longitude, raw_param.latitude))\n",
    "\n",
    "\n",
    "depth_sal = raw_coral.sjoin_nearest(raw_param, max_distance=0.5)\n",
    "\n",
    "depth_sal.to_csv('D:/TAMU Work/TAMU 2022 SPRING/OCEN 460/depthtempsaloxy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. To resolve the stratified nature of the WOA data, the following code is used to select the corresponding WOA column for the DSC depth of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = 'D:/TAMU Work/TAMU 2022 SPRING/OCEN 460/depthtempsaloxy.csv'\n",
    "\n",
    "raw = pd.read_csv(path)\n",
    "raw = raw[raw['depth'] <= 5500]\n",
    "skipped = 0\n",
    "for i in range(len(raw)):\n",
    "    try:\n",
    "        depth = str(raw['depth'][i])\n",
    "        raw['oxygen'][i] = raw[depth][i]\n",
    "    except KeyError:\n",
    "        skipped+=1\n",
    "        pass\n",
    "\n",
    "print(\"skipped:\", skipped)\n",
    "\n",
    "raw.to_csv('D:/TAMU Work/TAMU 2022 SPRING/OCEN 460/depthtempsaloxy_short.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The following code determines the maximum depth for each lat/long pair in the WOA dataset. These datapoints were then used to create a control dataset describing where coral is not present, in order to compare to the DSC dataset. Code displayed in sections 2 and 3 were used to add the temperature, salinity, and oxygen variables to the control dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = 'D:/TAMU Work/TAMU 2022 SPRING/OCEN 460/woa18_decav_t00mn04.csv'\n",
    "\n",
    "raw = pd.read_csv(path)\n",
    "depth = []\n",
    "\n",
    "for i in range(len(raw)):\n",
    "    for j in range(103):\n",
    "        curr = raw.iloc[i, -1-j]\n",
    "        plus = raw.iloc[i, -2-j\n",
    "        if j == 0 and np.isfinite(curr):\n",
    "            depth.append(raw.columns[-1])\n",
    "            break\n",
    "        elif np.isnan(curr) and np.isfinite(plus):\n",
    "            depth.append(raw.columns[-2-j])\n",
    "            break\n",
    "        elif j == 102:\n",
    "            depth.append(raw.columns[-1])\n",
    "print(len(depth))\n",
    "print(len(raw.latitude))\n",
    "out = pd.DataFrame({'latitude': raw.latitude,\n",
    "                    'longitude': raw.longitude,\n",
    "                    'depth': depth})\n",
    "\n",
    "out.to_csv('D:/TAMU Work/TAMU 2022 SPRING/OCEN 460/depths.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the final dataset had the following metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude | Longitude | Depth (m) | Temperature (c) | Salinity (ppt) | Dissolved Oxygen (umol/kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The following code visualizes the two datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reprocessed Data for Visualization\n",
    "path = str(pathlib.Path(os.getcwd())) + '\\processed_data\\combined_data_truncated.csv'\n",
    "raw = pd.read_csv(path)\n",
    "print(raw.describe())\n",
    "\n",
    "#Visualization\n",
    "coral_present_bool = raw[raw.coral_present == 1]\n",
    "plt.scatter(coral_present_bool['longitude'], coral_present_bool[\"latitude\"], s= 0.2)\n",
    "plt.title(\"Coral Growth Locations\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.xlim([-180,180])\n",
    "plt.ylim([-90,90])\n",
    "plt.show()\n",
    "\n",
    "coral_missing_bool = raw[raw.coral_present == 0]\n",
    "plt.scatter(coral_missing_bool['longitude'], coral_missing_bool[\"latitude\"], s= 0.2)\n",
    "plt.title(\"Locations Lacking Coral Growth (Control)\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.xlim([-180,180])\n",
    "plt.ylim([-90,90])\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of Coral Growth Datapoints:\", len(coral_present_bool))\n",
    "print(\"Number of Datapoints with no Coral Growth\", len(coral_missing_bool))\n",
    "\n",
    "plt.scatter(raw.longitude, raw.latitude, s=0.2, c=raw.depth)\n",
    "plt.title(\"Cumulative Dataset, Colored By Depth\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.xlim([-180,180])\n",
    "plt.ylim([-90,90])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.scatter(raw.longitude, raw.latitude, s=0.2, c=raw.temperature)\n",
    "plt.title(\"Cumulative Dataset, Colored By Temperature\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.xlim([-180,180])\n",
    "plt.ylim([-90,90])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.scatter(raw.longitude, raw.latitude, s=0.2, c=raw.salinity)\n",
    "plt.title(\"Cumulative Dataset, Colored By Salinity\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.xlim([-180,180])\n",
    "plt.ylim([-90,90])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.scatter(raw.longitude, raw.latitude, s=0.2, c=raw.oxygen)\n",
    "plt.title(\"Cumulative Dataset, Colored By Oxygen\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.xlim([-180,180])\n",
    "plt.ylim([-90,90])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
